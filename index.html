<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Pipeline ICG by SoaresGabriel</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Pipeline ICG</h1>
      <h2 class="project-tagline">Implementação de transformações geométricas em primitivas</h2>
      <a href="https://github.com/SoaresGabriel/PipelineICG" class="btn">View on GitHub</a>
      <a href="https://github.com/SoaresGabriel/PipelineICG/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/SoaresGabriel/PipelineICG/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="introdução" class="anchor" href="#introdu%C3%A7%C3%A3o" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introdução</h1>

<p>Este post faz parte do segundo trabalho da disciplina Introdução à Computação Gráfica, ministrada pelo Prof. Christian Azambuja Pagot da UFPB, no período 2016.1.</p>

<p>Deve ser implementado um Pipeline Gráfico, que é um conjunto de transformações geométricas em um objeto descrito inicialmente em um sistema de coordenadas próprio (ou Espaço do Objeto) e através dessas transformações, o levaremos ao Espaço da Tela, e o desenharemos usando os algoritmos usados e desenvolvidos no <a href="https://soaresgabriel.github.io/TrabalhoICG/">primeiro trabalho da disciplina</a>.</p>

<p>Além das ferramentas já usadas no primeiro trabalho, será usada também um objLoader (já disponibilizado pelo professor) para que possamos carregar o objeto a partir de um arquivo .obj, que descreve vértices e triângulos que compõe o objeto, e também será utilizado a biblioteca Eigen, para possibilitar operações entre matrizes e vetores.</p>

<h3>
<a id="espaço-homogêneo" class="anchor" href="#espa%C3%A7o-homog%C3%AAneo" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Espaço Homogêneo</h3>

<p>Faremos uso do Espaço Homogêneo nesse trabalho, veremos que ele possibilita a resolução de alguns problemas relacionado as transformações. Podemos derivar um Espaço Homogêneo, adicionando uma coordenada 'W' a pontos do espaço Euclidiano, chamamos essa de Coordenada Homogênea, dessa forma, um ponto no Espaço Euclidiano tem infinitos representantes no Espaço Homogêneo da seguinte forma:
<code>[Euclidiano] (X, Y, Z) ⇒ (X/W, Y/W, Z/W, W) [Homogêneo]</code></p>

<p>Dessa forma nesse trabalho, representaremos os vértices dos objetos, como pontos no espaço homogêneo, e usaremos inicialmente 'W=1' para simplificar, desse forma: <code>[Euclidiano] (X, Y, Z) ⇒ (X, Y, Z, 1) [Homogêneo]</code></p>

<p>Então basicamente aplicaremos um conjunto de transformações, que levará o objeto entre os seguintes espaços:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/pipelinespaces.png" alt="Passos do Pipeline"></p>

<p>Como já mencionado, temos um arquivo .obj que contem as informações do objeto em seu espaço, vamos agora ao primeiro conjunto de transformações:</p>

<h1>
<a id="espaço-do-objeto--espaço-do-universo" class="anchor" href="#espa%C3%A7o-do-objeto--espa%C3%A7o-do-universo" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Espaço do Objeto ⇒ Espaço do Universo</h1>

<p>Por conveniência os objetos são descritos num sistema de coordenadas próprio, denomidado o Espaço do Objeto, dessa forma cada objeto tem seu próprio espaço. Precisamos agora levar os objetos para um espaço em comum, onde todos os objetos estarão, esse espaço é denominado o Espaço do Universo.</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/objecttouniverse.png" alt="Levando objetos para o Espaço do Universo"></p>

<p>A transformação do espaço do Objeto para o Universo, se da simplesmente com transformações geométricas nos objetos, no exemplo acima, os dois objetos sofreram uma translação. Nos focaremos nas transformações mais fundamentais: Escala, Rotação e Translação, pois outras transformações podem ser obtidas como combinações dessas.</p>

<h2>
<a id="escala" class="anchor" href="#escala" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Escala</h2>

<p>A escala é simplesmente a mudança no tamanho do objeto, podemos alterar o tamanho do objeto igualmente entre todos os eixos (Escala Isotrópica), ou aplicar escalas diferentes para alguns eixos (Escala Anisotrópica), dessa forma, deformando o objeto.</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/Scales.png" alt="Escalas"></p>

<p>Sendo Sx, Sy e Sz, os fatores de escala para cada eixo, basicamente o que queremos é transformar o objeto da seguinte forma(Já usando a coordenada homogênea):</p>

<p><code>(X, Y, Z, 1) ⇒ (Sx*X, Sy*Y, Sz*Z, 1)</code></p>

<p>Podemos obter esse resultado multiplicando o vértice no formato Vetor Coluna, pela Matriz de Escala, da seguinte forma:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/ScaleOperation.png" alt="Matriz de Escala"></p>

<p>Observe que também conseguimos espalhar um objeto simplesmente aplicando uma escala negativa:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/mirroring.png" alt="Espelhamento"></p>

<h2>
<a id="rotação" class="anchor" href="#rota%C3%A7%C3%A3o" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Rotação</h2>

<p>Imagine um vetor w=(x,y) no plano, podemos representa-lo em coordenadas polares por <code>w=(r*cos(α), r*sen(α))</code>, onde r é a distância do ponto a origem, e α é o ângulo formado entre o vetor e o eixo x.
Agora queremos rotacionar esse vetor a um certo ângulo θ, obtendo o vetor <code>w'=(x', y')=(r*cos(α+θ), r*sen(α+θ))</code>, como na imagem:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/rotatingw.png" alt="Rotacionando Vetor"></p>

<p>Pelas propriedades de seno e cosseno, temos que:</p>

<blockquote>
<p>x'= rcos(α+θ) = rcos(α)cos(θ) − rsin(α)sin(θ)</p>

<p>y'= rsen(α+θ) = rsin(α)cos(θ) + rcos(α)sin(θ)</p>
</blockquote>

<p>Substituindo <code>x=rcos(α)</code> e <code>y=rsen(α)</code> nas equações anterior, temos que:</p>

<blockquote>
<p>x'= xcos(θ) − ysin(θ)</p>

<p>y'= xsin(θ) + ycos(θ)</p>
</blockquote>

<p>Dessa forma, poderíamos montar nossa matriz de rotação para esse caso, da seguinte forma:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/RotationMatrix2D.png" alt="Matriz de Rotação 2D"></p>

<p>Já no Espaço, que é onde nos interessa, temos mais possibilidades, temos que rotacionar ao redor de algum dos eixos, podemos usar procedimento análogo ao feito acima para encontrar a Matriz de Rotação para cada caso:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/RotationMatrixs3D.png" alt="Matrizes de Rotação 3D"></p>

<p>Observe como em cada caso, uma coordenada é mantida, confirmando em torno de qual eixo estamos rotacionando.</p>

<h2>
<a id="shear" class="anchor" href="#shear" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Shear</h2>

<p>O Shear é uma transformação que mantem o valor de uma coordenada enquanto a outra aumenta linearmente em relação aquela coordenada. Por exemplo, se aplicarmos um Shear em um quadrado no plano, ele ficará parecendo um monte de cartas inclinado:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/ShearTransformation.png" alt="Shear Transformation"></p>

<p>Neste trabalho não foi implementado o Shear, por três razões:
1. É pouco usado na prática.
2. No espaço temos 6 possibilidades de Shear, o que geraria uma matriz com muitos argumentos; e o mais importante:
3. Não é uma Transformação Fundamental, pois pode ser representada como uma combinação de escalas e rotações, como pode ser visto abaixo:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/ShearNotFundamental.png" alt="Shear com Escala e Rotação"></p>

<h2>
<a id="translação" class="anchor" href="#transla%C3%A7%C3%A3o" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Translação</h2>

<p>A translação nada mais é do que o deslocamento do objeto. Esse deslocamento pode ser feito simplesmente somando uma certa constante a coordenada dos vertices do objeto: (X,Y,Z) ⇒ (X+Dx,Y+Dy,Z+Dz).</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/Translation.png" alt="Translação"></p>

<p>No Espaço não conseguiríamos representar essa transformação com uma matriz 3x3, pois o deslocamento é uma constante, e qualquer elemento da matriz estaria multiplicando uma de suas coordenadas. 
Ai é que entra a coordenada homogênea, ao botarmos ela como 1 (na verdade pode ser qualquer valor, pois seria 'compensando' quando fizermos a divisão por w), e multiplicarmos o deslocamento por ela, estaremos apenas adicionando o próprio deslocamento que queríamos, ficando com a matriz dessa forma:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/TranslationMatrix.png" alt="Matriz de Translação"></p>

<h2>
<a id="matriz-model" class="anchor" href="#matriz-model" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Matriz Model</h2>

<p>Imagine que queremos aplicar uma escala <strong>S</strong> e depois uma rotação <strong>R</strong> em um vértice v1, originando o vértice v2.
Primeiro aplicamos a escala <code>vt = S*v1</code> e depois a rotação <code>v2 = R*vt</code>, como multiplicação de matrizes é associativa, poderíamos fazer o seguinte:</p>

<blockquote>
<p>v2 = R<em>vt = R</em>(S<em>v1) = (R</em>S)*v1</p>
</blockquote>

<p>Dessa forma poderíamos gerar uma matriz só <code>M= R*S</code> que seria multiplicado por todos os vértices do mesmo objeto. A essa matriz damos o nome de <em>Matriz Model</em> ou Matriz de Modelagem, e é formada pela multiplicação na ordem inversa de todas as matrizes de transformação a que um objeto vai ser sujeito, e ela é a responsável por levar um objeto do Espaço do Objeto para o Espaço do Universo.</p>

<p>Vale observar que a ordem das transformações geralmente importa, assim a ordem que multiplicamos as matrizes também importa e deve ser feita na ordem inversa a que as transformações vão ser aplicadas, como demonstrado acima. Para ilustrar, imagine duas matrizes de modelagem: <code>M1= T*R</code> onde é aplicada primeiro uma rotação e depois uma translação e <code>M2= R*T</code> onde as mesmas transformações são aplicadas na ordem inversa, poderíamos ter os seguintes resultados:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/TransformationOrder.png" alt="Ordem de Transformação"></p>

<h2>
<a id="implementação" class="anchor" href="#implementa%C3%A7%C3%A3o" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Implementação</h2>

<p>Dessa forma foi implementada a matriz de Modelagem, o seu conteúdo inicial é a matriz identidade (sem transformações), e ao chamarmos uma função de alguma transformação, a matriz de modelagem é multiplicada pela esquerda pela matriz da transformação, gerando a nova matriz de modelagem que aplicará as transformações na ordem em que forem chamadas.
O estado da matriz de modelagem é guardado entre os frames, de forma que se quisermos "zera-la" temos que chamar uma função especifica que carrega a matriz identidade novamente nela.</p>

<h1>
<a id="espaço-do-universo--espaço-da-câmera" class="anchor" href="#espa%C3%A7o-do-universo--espa%C3%A7o-da-c%C3%A2mera" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Espaço do Universo ⇒ Espaço da Câmera</h1>

<p>Para levar do espaço do universo para a câmera, mudaremos apenas a base do sistema de coordenadas. Primeiro definimos a câmera com alguns parâmetros, depois calculamos uma nova base de forma que a câmera fique na origem e olhando para a parte negativa do eixo z.</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/UniverseToCamera.png" alt="Mudando base do universo para câmera"></p>

<p>Neste trabalho, definiremos a câmera usando um ponto que será a posição ('p') da câmera, um ponto que indica para onde a câmera está olhando (lookAt 'l') e um vetor que indica a parte de cima da cena (vetor 'u'), para que a câmera não fique de cabeça para baixo por exemplo. Com a posição da câmera e o lookAt, podemos calcular o vetor da direção ao qual a câmera está olhando: d= l-p.</p>

<p>Como queremos que a câmera olhe para o z negativo, o z da câmera (Zc) pode ser o vetor de sentido contrário ao vetor direção. Queremos ainda que a base será ortonormal (veremos depois uma vantagem), então normalizaremos (dividimos as coordenadas pelo modulo do próprio vetor, para que se origine um vetor de mesmo sentido, mas de modulo 1) todos os vetores da base.</p>

<p>O vetor up, está no plano ZY da câmera, portanto um vetor que será perpendicular ao plano ZU (U=up), será perpendicular a z e a y, portanto podemos encontrar o Xc da câmera fazendo o produto vetorial 'Zc x U' (nesta ordem para um sistema de mão direita), e normalizamos.</p>

<p>Agora o eixo Yc pode ser obtido da mesma forma fazendo o produto vetorial 'Zc x Xc' e normalizamos.
Dessa forma ficamos com o seguinte: </p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/CameraBase.png" alt="Base da Câmera"></p>

<p>Dessa forma, podemos montar uma matriz B cujas colunas são os vetores da base da câmera, que seria a matriz que transformaria da câmera para o universo. Como queremos a transformação inversa, temos que calcular a matriz inversa. Mas como a matriz B é ortonormal, por ser formada por vetores ortonormais, então podemos calcular a inversa simplesmente transpondo B, e essa matriz transforma do espaço do universo para a câmera.</p>

<p>Mas essa matriz que montamos, leva apenas em consideração a rotação dos sistemas de coordenadas, nos casos que as origens são diferentes, precisamos ainda fazer uma translação. Essa translação é simples, basta transladar os objetos referente a posição da câmera, que será a nova origem, dai podemos montar uma matriz T de translação.</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/ViewMatrixs.png" alt="Matrizes de Rotação e Translação da Câmera"></p>

<h2>
<a id="matriz-view" class="anchor" href="#matriz-view" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Matriz View</h2>

<p>Aplicando a mesma lógica que fizemos com a matriz Model, definiremos a matriz View como sendo a combinação da translação e depois da rotação <code>VIEW=Bt*T</code>. Dessa forma a matriz VIEW leva os objetos do espaço do universo para o espaço da câmera.
Assim foi implementada uma função "defineCamera" que recebe a posição da câmera, o lookAt e o up, e já calcula a matriz View.</p>

<p>Espaço da Câmera ⇒ Espaço de Recorte
Basicamente o que faremos aqui, é aplicar uma distorção perspectiva nos objetos, de forma que objetos mais longes, pareçam menores do que objetos mais pertos. A matriz que desenvolveremos é uma mais simples, que leva em consideração o View Plane, como veremos.</p>

<p>Primeiro deslocamos a câmera uma distância 'd' para o eixo positivo z, o que podemos fazer através dessa matriz:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/CameraTransMatrix.png" alt="Matriz de Translação para a Câmera"></p>

<p>Criaremos um view plano no eixo y, e projetamos os vértices do objeto contra esse view plane em relação a posição da câmera, de forma que obtemos uma nova altura para o objeto:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/PerspProjection.png" alt="Projeção no View Plane"></p>

<p>De semelhança de triângulos, vem que:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/PerspectiveY.png" alt=""></p>

<p>Aplicamos procedimento semelhante na coordenada X, e para o Z, também dividiremos pelo mesmo fator, embora não fosse exatamente o que queríamos, não teremos problema, pois essa divisão não mudará a ordem dos vértices em relação ao eixo Z, e dessa forma, poderemos gerar a mesma imagem final sem problemas. Assim ficamos com: </p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/PerspProjCoord.png" alt=""></p>

<p>Como as três coordenadas tem um fator em comum, podemos representar esse novo ponto no espaço homogêneo, apenas mudando a coordenada homogênea para esse fator em comum, pois ao transformar este ponto para o espaço euclidiano, dividiremos as coordenadas pela coordenada homogênea.</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/ProjVertex.png" alt=""></p>

<p>Assim, podemos montar uma matriz que muda a coordenada homogênea para esse fator:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/PerspMatrix.png" alt=""></p>

<h2>
<a id="matriz-projection" class="anchor" href="#matriz-projection" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Matriz Projection</h2>

<p>Agora montamos nossa matriz projection, que é a matriz que leva do espaço da câmera para o espaço de recorte, e é formada pela translação, com a distorção que desenvolvemos, ficando com:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/ProjectionMatrix.png" alt="Matriz Projection"></p>

<p>Dessa forma, foi implementada uma função que recebe o parâmetro 'd' e já calcula a Matriz Projection. Vale ressaltar que o parâmetro d vai definir o quanto de distorção perspectiva nossa cena terá.</p>

<h2>
<a id="espaço-de-recorte--espaço-canônico" class="anchor" href="#espa%C3%A7o-de-recorte--espa%C3%A7o-can%C3%B4nico" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Espaço de Recorte ⇒ Espaço Canônico</h2>

<p>O espaço canônico será o espaço em que toda a cena visível estaria dentro de um cubo que vai de (-1,-1,-1) a (1,1,1), mas como desenvolvemos uma matriz mais simples, não temos essa garantia, por tanto o espaço canônico no escopo desse trabalho não é bem canônico, mas será o suficiente para nós.</p>

<p>Quando transformamos do espaço da câmera para o espaço de recorte, basicamente aplicamos uma translação nos vértices e mudamos a coordenada homogênea para um fator ao qual as coordenadas deveriam serem posteriormente divididas. Então a transformação do espaço de recorte para o espaço canônico, é apenas isso, pegamos cada vértice e dividimos por sua coordenada homogênea W, voltando a um ponto da forma (X,Y,Z,1), onde (X,Y,Z) serão os vértices novamente no espaço euclidiano.</p>

<h2>
<a id="espaço-canônico--espaço-de-tela" class="anchor" href="#espa%C3%A7o-can%C3%B4nico--espa%C3%A7o-de-tela" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Espaço Canônico ⇒ Espaço de Tela</h2>

<p>Agora a cena será levada ao espaço de tela, onde as coordenadas corresponderão a pixeis na tela de visualização.
Como falado acima, no espaço canônico ideal, a cena estaria em um cubo que vai de (-1,-1,-1) a (1,1,1). A câmera está no eixo z olhando para lado negativo do eixo, então é como se projetássemos a cena em um certo plano XY, já que o espaço de tela é bidimensional, dessa forma será manipulada as coordenadas XY dos vértices, para que correspondam as coordenadas no espaço de tela.
O primeira coisa que observamos é que na tela, o eixo Y cresce para baixo, por isso a primeira coisa que fazemos é espelhar o eixo Y, o que pode ser feito aplicando uma escala de -1:</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/S1Matrix.png" alt=""></p>

<p>O espaço de tela também não tem coordenadas negativas, então podem-se aplicar uma translação de 1 em x e em y, para que a cena fique no intervalo (0,0) à (2,2) (considerando apenas XY).</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/TMatrix.png" alt=""></p>

<p>Sendo W a largura da tela e H a altura da tela, então o espaço de tela vai de (0,0) à (W-1, H-1), então aplica-se uma escala de (W-1)/2 em X e (H-1)/2 em Y, para que a cena fique nesse intervalo.</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/S2Matrix.png" alt=""></p>

<p>Como o espaço de tela tem apenas coordenadas inteiras, depois disso, basta arredondar as coordenadas dos vértices, para obter uma aproximação no espaço de tela.</p>

<h2>
<a id="matriz-viewport" class="anchor" href="#matriz-viewport" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Matriz ViewPort</h2>

<p>Agora pode-se montar a matriz ViewPort como a combinação das transformações anteriores <code>ViewPort= S2*T*S1</code>, e ela quem leva do espaço canônico para o espaço de tela. Então foi implementada uma função que recebe a largura e a altura da janela de visualização e calcula a matriz ViewPort.</p>

<h1>
<a id="implementação-1" class="anchor" href="#implementa%C3%A7%C3%A3o-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Implementação</h1>

<p>Agora já foram implementadas as matrizes que levam por cada espaço do pipeline, foram desenvolvidas funções que calculam essas matrizes, conforme foi falado ao longo desse post.</p>

<p>A ideia como falado anteriormente é combinar as matrizes para que posteriormente, para que seja possível multiplicar nossos vértices por uma matriz só que faça todas as transformações necessárias, diminuindo assim o número total de operações.</p>

<p>Então quando for desenhar um objeto, após ser gerada cada matriz nos procedimentos falados nos outros tópicos, será feito o seguinte: Primeiro gera-se a matriz <code>MODELVIEWPROJECTION= PROJECTION*VIEW*MODEL</code> essa matriz levará os vértices do espaço do objeto, direto para o espaço de recorte, depois divide-se cada vértice por sua coordenada homogênea W, para levar os vértices do espaço de recorte para o espaço canônico, e por último multiplica-se os vértices pela matriz VIEWPORT, para levar do espaço canônico para o espaço de tela.</p>

<p>Conforme falado pelo Prof. Christian, e confirmado em testes, pode-se deixar a divisão por W para o final que o resultado será idêntico, dessa forma pode-se gerar a matriz <code>MVPV = VIEWPORT*PROJECTION*VIEW*MODEL</code>, então multiplica-se os vértices por essa matriz e depois se faz a divisão por W, diminuindo mais ainda o número de operações e obtendo o mesmo resultado.</p>

<p>Com o objLoader, é carregado um triângulo por vez (3 vértices), aplicado as transformações acima nos 3 vértices, depois para cada vértice, é gerado um struct Pixel (implementado no trabalho 1), onde as coordenadas são as mesmas coordenadas XY de cada vértice após serem truncadas, e desses 3 structs Pixel's é gerado um struct Triangle (trabalho anterior), e é chamada a função drawTriangle, que também foi implementada no trabalho anterior, para desenhar esse triângulo na tela. Após todos os triângulos serem desenhados, o objeto já deve aparecer corretamente na tela.</p>

<h1>
<a id="resultados" class="anchor" href="#resultados" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Resultados</h1>

<p>Agora que já temos o pipeline implementado, vamos ver os resultados. Será usado o obj disponibilizado pelo prof. Christian, de forma que o resultado deva estar parecido com o resultado gerado pelo OpenGL no programa que o professor disponibilizou.</p>

<p>A principio não foi aplicada nenhuma transformação no objeto em si, então a matriz model será apenas a identidade. A câmera foi posicionada em (0,0,5), com lookAt para a origem (0,0,0) e UP (0,1,0). E o parâmetro d da matriz de projeção (distancia do viewplane) foi definido para d=1.</p>

<p>Abaixo temos o resultado, a direita é a imagem gerada pelo programa do professor usando OpenGL, ao qual deve se aproximar, e a direita a imagem gerada pela implementação aqui desenvolvida.</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/1result.png" alt="Primeiro Resultado"></p>

<p>Então foi modificado o parâmetro d e observado que 'd=2.4' gerava a imagem com o mesmo tamanho, porém se observamos mais cuidadosamente, alguns detalhes da imagem ficaram diferentes (a seta mostra um desses detalhes). </p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/2result.png" alt="Segundo Resultado"></p>

<p>Isso aconteceu porque a distorção perspectiva foi aplicada diferente entre as imagens, então foi percebido que deve-se também mudar a posição da câmera juntamente com o d, para se obter uma imagem mais aproximada. Nos testes foi percebido que a câmera na posição (0,0,4) e o d=1.92 foi o que gerou a imagem mais aproximada.</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/3result.png" alt="Terceiro Resultado"></p>

<p>E agora vejamos usando alguns modelos mais elaborados: (foram aplicadas algumas transformações na model, para melhorar a visualização)</p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/eagleresult.png" alt=""></p>

<p><img src="https://soaresgabriel.github.io/PipelineICG/images/pantherresult.png" alt=""></p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/SoaresGabriel/PipelineICG">Pipeline ICG</a> is maintained by <a href="https://github.com/SoaresGabriel">SoaresGabriel</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
